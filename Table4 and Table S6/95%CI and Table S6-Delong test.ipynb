{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "337d8a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import uniform\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy import stats\n",
    "from sklearn. metrics import roc_curve, auc\n",
    "import random\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from sklearn.calibration import CalibrationDisplay\n",
    "from sklearn. metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a4976b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred):\n",
    "    tp = np.sum(np.logical_and(y_true == 1, y_pred == 1))\n",
    "    tn = np.sum(np.logical_and(y_true == 0, y_pred == 0))\n",
    "    fp = np.sum(np.logical_and(y_true == 0, y_pred == 1))\n",
    "    fn = np.sum(np.logical_and(y_true == 1, y_pred == 0))\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    ppv = tp / (tp + fp)\n",
    "    npv = tn / (tn + fn)\n",
    "    predictive_accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    mcc = (tp * tn - fp * fn) / np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "    return sensitivity, specificity, ppv, npv, predictive_accuracy, mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e382b271",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"C:\\\\Users\\\\12292\\\\Desktop\\\\train size - xx (2).xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c681194",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = data.iloc[:, 1:]  # Features (excluding the first column)\n",
    "train_y = data.iloc[:, 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ab91f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BNF</th>\n",
       "      <th>PHASES</th>\n",
       "      <th>Radscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.260731</td>\n",
       "      <td>4</td>\n",
       "      <td>0.446201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.385450</td>\n",
       "      <td>9</td>\n",
       "      <td>2.553235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.410795</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.116113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.930106</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.127136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.066182</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.669537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>1.266495</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.748227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>1.018247</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.270338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>0.658511</td>\n",
       "      <td>5</td>\n",
       "      <td>0.754189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>1.007611</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.795665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>1.074153</td>\n",
       "      <td>3</td>\n",
       "      <td>0.604769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          BNF  PHASES  Radscore\n",
       "0    1.260731       4  0.446201\n",
       "1    1.385450       9  2.553235\n",
       "2    1.410795       0 -1.116113\n",
       "3    0.930106       0 -1.127136\n",
       "4    1.066182       0 -1.669537\n",
       "..        ...     ...       ...\n",
       "328  1.266495       1 -0.748227\n",
       "329  1.018247       1 -1.270338\n",
       "330  0.658511       5  0.754189\n",
       "331  1.007611       6 -0.795665\n",
       "332  1.074153       3  0.604769\n",
       "\n",
       "[333 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dd608fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_R = data.iloc[:,3]  # Features (excluding the first column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a04a9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.446201\n",
       "1      2.553235\n",
       "2     -1.116113\n",
       "3     -1.127136\n",
       "4     -1.669537\n",
       "         ...   \n",
       "328   -0.748227\n",
       "329   -1.270338\n",
       "330    0.754189\n",
       "331   -0.795665\n",
       "332    0.604769\n",
       "Name: Radscore, Length: 333, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5cd329f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "328    0\n",
       "329    0\n",
       "330    1\n",
       "331    0\n",
       "332    1\n",
       "Name: status, Length: 333, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ccd09c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_P = data.iloc[:,2]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10b3a503",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_excel(\"C:\\\\Users\\\\12292\\\\Desktop\\\\test size - xx (2).xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1006072b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = data_test.iloc[:, 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfa7d456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BNF</th>\n",
       "      <th>PHASES</th>\n",
       "      <th>Radscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.599177</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.199217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.277627</td>\n",
       "      <td>4</td>\n",
       "      <td>0.417314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.932445</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.781816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.956438</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.183729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.548727</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.510796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>1.190633</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.118190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>1.035633</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.140353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1.178697</td>\n",
       "      <td>4</td>\n",
       "      <td>1.206319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1.069052</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.283198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1.273815</td>\n",
       "      <td>4</td>\n",
       "      <td>0.457788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          BNF  PHASES  Radscore\n",
       "0    1.599177       6 -0.199217\n",
       "1    1.277627       4  0.417314\n",
       "2    0.932445       1 -0.781816\n",
       "3    0.956438       5 -0.183729\n",
       "4    1.548727       3 -0.510796\n",
       "..        ...     ...       ...\n",
       "137  1.190633       4 -1.118190\n",
       "138  1.035633       0 -1.140353\n",
       "139  1.178697       4  1.206319\n",
       "140  1.069052       0 -1.283198\n",
       "141  1.273815       4  0.457788\n",
       "\n",
       "[142 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X = data_test.iloc[:, 1:4] \n",
    "test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c42589f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BNF</th>\n",
       "      <th>PHASES</th>\n",
       "      <th>Radscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.599177</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.199217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.277627</td>\n",
       "      <td>4</td>\n",
       "      <td>0.417314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.932445</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.781816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.956438</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.183729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.548727</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.510796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>1.190633</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.118190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>1.035633</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.140353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1.178697</td>\n",
       "      <td>4</td>\n",
       "      <td>1.206319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1.069052</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.283198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1.273815</td>\n",
       "      <td>4</td>\n",
       "      <td>0.457788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          BNF  PHASES  Radscore\n",
       "0    1.599177       6 -0.199217\n",
       "1    1.277627       4  0.417314\n",
       "2    0.932445       1 -0.781816\n",
       "3    0.956438       5 -0.183729\n",
       "4    1.548727       3 -0.510796\n",
       "..        ...     ...       ...\n",
       "137  1.190633       4 -1.118190\n",
       "138  1.035633       0 -1.140353\n",
       "139  1.178697       4  1.206319\n",
       "140  1.069052       0 -1.283198\n",
       "141  1.273815       4  0.457788\n",
       "\n",
       "[142 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28646305",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_R = data_test.iloc[:,3]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f202c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      1\n",
       "4      0\n",
       "      ..\n",
       "137    0\n",
       "138    0\n",
       "139    1\n",
       "140    0\n",
       "141    1\n",
       "Name: status, Length: 142, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df460ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy with Best Parameters: 0.795774647887324\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf_params = {\n",
    "    'n_estimators': 210,\n",
    "    'random_state':9999,\n",
    "    'max_depth':3,\n",
    "    'min_samples_leaf':34,\n",
    "    'min_samples_split':70,\n",
    "}\n",
    "\n",
    "best_RF = RandomForestClassifier(**rf_params)\n",
    "\n",
    "best_RF.fit(train_X, train_y)\n",
    "RF_y_pred = best_RF.predict(test_X)\n",
    "accuracy = accuracy_score(test_y, RF_y_pred)\n",
    "print(\"Test Accuracy with Best Parameters:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e16332ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8803980099502487"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(test_y,  RF_y_pred)\n",
    "RF_y_score = best_RF.predict_proba(test_X)[:, 1]\n",
    "fprrf,tprrf,threshold = roc_curve(test_y,RF_y_score)\n",
    "auc(fprrf,tprrf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cee8930b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original AUC: 0.880\n",
      "95% CI for AUC: (0.824, 0.941)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Calculate ROC curve and AUC for the original data\n",
    "fprrf, tprrf, thresholds = roc_curve(test_y, RF_y_score)\n",
    "original_auc = auc(fprrf, tprrf)\n",
    "print(\"Original AUC: {:.3f}\".format(original_auc))\n",
    "\n",
    "# Bootstrapping parameters\n",
    "n_bootstraps = 1000  # You can adjust this number as needed\n",
    "auc_scores = []\n",
    "\n",
    "# Bootstrapping process\n",
    "np.random.seed(321)  # Set random seed for reproducibility\n",
    "for _ in range(n_bootstraps):\n",
    "    # Randomly sample test set samples with replacement\n",
    "    bootstrap_indices = np.random.randint(0, len(test_y), size=len(test_y))\n",
    "    bootstrap_y = test_y[bootstrap_indices]\n",
    "    bootstrap_y_score = RF_y_score[bootstrap_indices]\n",
    "    \n",
    "    # Calculate AUC for each bootstrap sample\n",
    "    fpr_bootstrap, tpr_bootstrap, _ = roc_curve(bootstrap_y, bootstrap_y_score)\n",
    "    auc_bootstrap = auc(fpr_bootstrap, tpr_bootstrap)\n",
    "    auc_scores.append(auc_bootstrap)\n",
    "\n",
    "# Calculate the 95% confidence interval\n",
    "auc_scores = np.array(auc_scores)\n",
    "auc_scores_sorted = np.sort(auc_scores)\n",
    "n = len(auc_scores)\n",
    "lower_idx = int(np.round(n * 0.025))  # Calculate lower bound index\n",
    "upper_idx = int(np.round(n * 0.975))  # Calculate upper bound index\n",
    "auc_lower = auc_scores_sorted[lower_idx]\n",
    "auc_upper = auc_scores_sorted[upper_idx]\n",
    "\n",
    "print(\"95% CI for AUC: ({:.3f}, {:.3f})\".format(auc_lower, auc_upper))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30b73df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original AUC: 0.916\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "# Predict on the training set\n",
    "RF_train_y_pred = best_RF.predict(train_X)\n",
    "train_y_prob = best_RF.predict_proba(train_X)[:, 1]\n",
    "\n",
    "# Calculate AUC\n",
    "train_auc = roc_auc_score(train_y, train_y_prob)\n",
    "\n",
    "# Calculate ROC curve and AUC for the original data\n",
    "fprRF, tprRF, thresholds = roc_curve(train_y, train_y_prob)\n",
    "original_auc = auc(fprRF, tprRF)\n",
    "print(\"Original AUC: {:.3f}\".format(original_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9bec9768",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "train_y_prob = best_RF.predict_proba(train_X)[:, 1]\n",
    "\n",
    "train_auc = roc_auc_score(train_y, train_y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88b492ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original AUC: 0.916\n",
      "95% CI for AUC on training set: (0.884, 0.943)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy.stats import percentileofscore\n",
    "\n",
    "# Calculate original AUC\n",
    "fprRF, tprRF, thresholds = roc_curve(train_y, train_y_prob)\n",
    "original_auc = auc(fprRF, tprRF)\n",
    "print(\"Original AUC: {:.3f}\".format(original_auc))\n",
    "\n",
    "# Bootstrapping parameters\n",
    "n_bootstraps = 1000  # You can adjust this number as needed\n",
    "auc_scores = []\n",
    "\n",
    "# Bootstrapping process\n",
    "np.random.seed(321)  # Set random seed for reproducibility\n",
    "for _ in range(n_bootstraps):\n",
    "    # Randomly sample training set samples with replacement\n",
    "    bootstrap_indices = np.random.randint(0, len(train_y), size=len(train_y))\n",
    "    bootstrap_y = train_y[bootstrap_indices]\n",
    "    bootstrap_y_score = train_y_prob[bootstrap_indices]\n",
    "    \n",
    "    # Calculate AUC for each bootstrap sample\n",
    "    fpr_bootstrap, tpr_bootstrap, _ = roc_curve(bootstrap_y, bootstrap_y_score)\n",
    "    auc_bootstrap = auc(fpr_bootstrap, tpr_bootstrap)\n",
    "    auc_scores.append(auc_bootstrap)\n",
    "\n",
    "# Calculate the 95% confidence interval\n",
    "auc_scores = np.array(auc_scores)\n",
    "auc_scores_sorted = np.sort(auc_scores)\n",
    "n = len(auc_scores)\n",
    "lower_idx = int(np.round(n * 0.025))  # Calculate lower bound index\n",
    "upper_idx = int(np.round(n * 0.975))  # Calculate upper bound index\n",
    "auc_lower = auc_scores_sorted[lower_idx]\n",
    "auc_upper = auc_scores_sorted[upper_idx]\n",
    "\n",
    "print(\"95% CI for AUC on training set: ({:.3f}, {:.3f})\".format(auc_lower, auc_upper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73f06d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Metrics:\n",
      "Sensitivity: 0.823\n",
      "Specificity: 0.844\n",
      "PPV (Precision): 0.807\n",
      "NPV: 0.858\n",
      "Predictive Accuracy: 0.835\n",
      "MCC: 0.666\n",
      "\n",
      "Test Set Metrics:\n",
      "Sensitivity: 0.746\n",
      "Specificity: 0.840\n",
      "PPV (Precision): 0.806\n",
      "NPV: 0.787\n",
      "Predictive Accuracy: 0.796\n",
      "MCC: 0.590\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics for the training and test sets\n",
    "sensitivity_train, specificity_train, ppv_train, npv_train, predictive_accuracy_train, mcc_train = calculate_metrics(train_y, RF_train_y_pred)\n",
    "sensitivity_test, specificity_test, ppv_test, npv_test, predictive_accuracy_test, mcc_test = calculate_metrics(test_y, RF_y_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"Train Set Metrics:\")\n",
    "print(f\"Sensitivity: {sensitivity_train:.3f}\")\n",
    "print(f\"Specificity: {specificity_train:.3f}\")\n",
    "print(f\"PPV (Precision): {ppv_train:.3f}\")\n",
    "print(f\"NPV: {npv_train:.3f}\")\n",
    "print(f\"Predictive Accuracy: {predictive_accuracy_train:.3f}\")\n",
    "print(f\"MCC: {mcc_train:.3f}\")\n",
    "\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "print(f\"Sensitivity: {sensitivity_test:.3f}\")\n",
    "print(f\"Specificity: {specificity_test:.3f}\")\n",
    "print(f\"PPV (Precision): {ppv_test:.3f}\")\n",
    "print(f\"NPV: {npv_test:.3f}\")\n",
    "print(f\"Predictive Accuracy: {predictive_accuracy_test:.3f}\")\n",
    "print(f\"MCC: {mcc_test:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef83a1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-squared: 12.431163258692122\n",
      "P-value: 0.1900789131095703\n",
      "Degrees of freedom: 8\n",
      "The model is well calibrated.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "from scipy.stats import chi2_contingency  \n",
    "\n",
    "def hosmer_lemeshow_test(test_y, RF_y_pred, num_groups=10):  \n",
    "    # Sort the data based on predicted probabilities  \n",
    "    sorted_indices = np.argsort(RF_y_pred)  \n",
    "    sorted_y = test_y[sorted_indices]  \n",
    "    \n",
    "    # Create groups based on the sorted indices  \n",
    "    group_size = len(sorted_y) // num_groups  \n",
    "    group_bounds = np.arange(0, len(sorted_y) + 1, group_size)  \n",
    "    \n",
    "    # Calculate observed and expected counts for each group  \n",
    "    observed_counts = np.zeros(num_groups)  \n",
    "    expected_counts = np.zeros(num_groups)  \n",
    "    \n",
    "    total_positive = np.sum(sorted_y)  \n",
    "    total_negative = len(sorted_y) - total_positive  \n",
    "    \n",
    "    for i in range(num_groups):  \n",
    "        start, end = group_bounds[i], group_bounds[i + 1]  \n",
    "        observed_counts[i] = np.sum(sorted_y[start:end])  \n",
    "        expected_counts[i] = (end - start) * total_positive / len(sorted_y)  \n",
    "        \n",
    "    # Perform chi-squared test  \n",
    "    chi2, p = chi2_contingency(np.array([observed_counts, expected_counts]).T)[:2]  \n",
    "    \n",
    "    dof = num_groups - 2  # Degrees of freedom for chi-squared test\n",
    "      \n",
    "    return chi2, p, dof  \n",
    "\n",
    "chi2, p_value, dof = hosmer_lemeshow_test(test_y,RF_y_pred)  \n",
    "print(f\"Chi-squared: {chi2}\")  \n",
    "print(f\"P-value: {p_value}\")  \n",
    "print(f\"Degrees of freedom: {dof}\")\n",
    "\n",
    "# Determining Model Calibration Based on P-Value\n",
    "if p_value < 0.05:\n",
    "    print(\"The model is poorly calibrated.\")\n",
    "else:\n",
    "    print(\"The model is well calibrated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af865455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.4, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.0395, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=7, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=254, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=527, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.4, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.0395, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=7, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=254, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=527, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.4, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.0395, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=7, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=254, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=527, ...)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import xgboost as xgb\n",
    "best_model_XGB = xgb.XGBClassifier(n_estimators=254, learning_rate=0.0395, max_depth=3, min_child_weight=7,colsample_bytree=0.4, \n",
    "                                   subsample=0.4,random_state=527)\n",
    "\n",
    "best_model_XGB.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a857c046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9128081340062908"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_train_y_pred = best_model_XGB.predict(train_X)\n",
    "XGBboost_train_y_score = best_model_XGB.predict_proba(train_X)[:, 1]\n",
    "fprXGB,tprXGB,threshold = roc_curve(train_y,XGBboost_train_y_score)\n",
    "auc(fprXGB,tprXGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6d72b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8877611940298507"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_y_pred = best_model_XGB.predict(test_X)\n",
    "XGBboost_y_score = best_model_XGB.predict_proba(test_X)[:, 1]\n",
    "fprxgb,tprxgb,threshold = roc_curve(test_y,XGBboost_y_score)\n",
    "auc(fprxgb,tprxgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54fdbf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "train_y_prob =best_model_XGB.predict_proba(train_X)[:, 1]\n",
    "\n",
    "train_auc = roc_auc_score(train_y, train_y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e009ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original AUC: 0.888\n",
      "95% CI for AUC: (0.831, 0.946)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Calculate ROC curve and AUC for the original data\n",
    "fprxgb, tprxgb, thresholds = roc_curve(test_y, XGBboost_y_score )\n",
    "original_auc = auc(fprxgb, tprxgb)\n",
    "print(\"Original AUC: {:.3f}\".format(original_auc))\n",
    "\n",
    "# Bootstrapping parameters\n",
    "n_bootstraps = 1000  # You can adjust this number as needed\n",
    "auc_scores = []\n",
    "\n",
    "# Bootstrapping process\n",
    "np.random.seed(321)  # Set random seed for reproducibility\n",
    "for _ in range(n_bootstraps):\n",
    "    # Randomly sample test set samples with replacement\n",
    "    bootstrap_indices = np.random.randint(0, len(test_y), size=len(test_y))\n",
    "    bootstrap_y = test_y[bootstrap_indices]\n",
    "    bootstrap_y_score = XGBboost_y_score[bootstrap_indices]\n",
    "    \n",
    "    # Calculate AUC for each bootstrap sample\n",
    "    fpr_bootstrap, tpr_bootstrap, _ = roc_curve(bootstrap_y, bootstrap_y_score)\n",
    "    auc_bootstrap = auc(fpr_bootstrap, tpr_bootstrap)\n",
    "    auc_scores.append(auc_bootstrap)\n",
    "\n",
    "# Calculate the 95% confidence interval\n",
    "auc_scores = np.array(auc_scores)\n",
    "auc_scores_sorted = np.sort(auc_scores)\n",
    "n = len(auc_scores)\n",
    "lower_idx = int(np.round(n * 0.025))  # Calculate lower bound index\n",
    "upper_idx = int(np.round(n * 0.975))  # Calculate upper bound index\n",
    "auc_lower = auc_scores_sorted[lower_idx]\n",
    "auc_upper = auc_scores_sorted[upper_idx]\n",
    "\n",
    "print(\"95% CI for AUC: ({:.3f}, {:.3f})\".format(auc_lower, auc_upper))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0aeaa161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original AUC: 0.913\n",
      "95% CI for AUC: (0.881, 0.941)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Calculate ROC curve and AUC for the original data\n",
    "fprxgb, tprxgb, thresholds = roc_curve(train_y,XGBboost_train_y_score )\n",
    "original_auc = auc(fprXGB, tprXGB)\n",
    "print(\"Original AUC: {:.3f}\".format(original_auc))\n",
    "\n",
    "# Bootstrapping parameters\n",
    "n_bootstraps = 1000  # You can adjust this number as needed\n",
    "auc_scores = []\n",
    "\n",
    "# Bootstrapping process\n",
    "np.random.seed(321)  # Set random seed for reproducibility\n",
    "for _ in range(n_bootstraps):\n",
    "    # Randomly sample train set samples with replacement\n",
    "    bootstrap_indices = np.random.randint(0, len(train_y), size=len(train_y))\n",
    "    bootstrap_y = train_y[bootstrap_indices]\n",
    "    bootstrap_y_score = XGBboost_train_y_score[bootstrap_indices]\n",
    "    \n",
    "    # Calculate AUC for each bootstrap sample\n",
    "    fpr_bootstrap, tpr_bootstrap, _ = roc_curve(bootstrap_y, bootstrap_y_score)\n",
    "    auc_bootstrap = auc(fpr_bootstrap, tpr_bootstrap)\n",
    "    auc_scores.append(auc_bootstrap)\n",
    "\n",
    "# Calculate the 95% confidence interval\n",
    "auc_scores = np.array(auc_scores)\n",
    "auc_scores_sorted = np.sort(auc_scores)\n",
    "n = len(auc_scores)\n",
    "lower_idx = int(np.round(n * 0.025))  # Calculate lower bound index\n",
    "upper_idx = int(np.round(n * 0.975))  # Calculate upper bound index\n",
    "auc_lower = auc_scores_sorted[lower_idx]\n",
    "auc_upper = auc_scores_sorted[upper_idx]\n",
    "\n",
    "print(\"95% CI for AUC: ({:.3f}, {:.3f})\".format(auc_lower, auc_upper))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "685393cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Metrics:\n",
      "Sensitivity: 0.8367\n",
      "Specificity: 0.8441\n",
      "PPV (Precision): 0.8092\n",
      "NPV: 0.8674\n",
      "Predictive Accuracy: 0.8408\n",
      "MCC: 0.6787\n",
      "\n",
      "Test Set Metrics:\n",
      "Sensitivity: 0.7612\n",
      "Specificity: 0.8667\n",
      "PPV (Precision): 0.836\n",
      "NPV: 0.8025\n",
      "Predictive Accuracy: 0.8169\n",
      "MCC: 0.6332\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "sensitivity_train, specificity_train, ppv_train, npv_train, predictive_accuracy_train, mcc_train = calculate_metrics(train_y,XGB_train_y_pred)\n",
    "sensitivity_test, specificity_test, ppv_test, npv_test, predictive_accuracy_test, mcc_test = calculate_metrics(test_y,XGB_y_pred)\n",
    "\n",
    "print(\"Train Set Metrics:\")\n",
    "print(f\"Sensitivity: {sensitivity_train:.4f}\")\n",
    "print(f\"Specificity: {specificity_train:.4f}\")\n",
    "print(f\"PPV (Precision): {ppv_train:.4f}\")\n",
    "print(f\"NPV: {npv_train:.4f}\")\n",
    "print(f\"Predictive Accuracy: {predictive_accuracy_train:.4f}\")\n",
    "print(f\"MCC: {mcc_train:.4f}\")\n",
    "\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "print(f\"Sensitivity: {sensitivity_test:.4f}\")\n",
    "print(f\"Specificity: {specificity_test:.4f}\")\n",
    "print(f\"PPV (Precision): {ppv_test:.3f}\")\n",
    "print(f\"NPV: {npv_test:.4f}\")\n",
    "print(f\"Predictive Accuracy: {predictive_accuracy_test:.4f}\")\n",
    "print(f\"MCC: {mcc_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "71a073b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-squared: 16.102124381629054\n",
      "P-value: 0.06477934921791016\n",
      "Degrees of freedom: 8\n",
      "The model is well calibrated.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "from scipy.stats import chi2_contingency  \n",
    "\n",
    "def hosmer_lemeshow_test(test_y, XGB_y_pred , num_groups=10):  \n",
    "    # Sort the data based on predicted probabilities  \n",
    "    sorted_indices = np.argsort(XGB_y_pred)  \n",
    "    sorted_y = test_y[sorted_indices]  \n",
    "    \n",
    "    # Create groups based on the sorted indices  \n",
    "    group_size = len(sorted_y) // num_groups  \n",
    "    group_bounds = np.arange(0, len(sorted_y) + 1, group_size)  \n",
    "    \n",
    "    # Calculate observed and expected counts for each group  \n",
    "    observed_counts = np.zeros(num_groups)  \n",
    "    expected_counts = np.zeros(num_groups)  \n",
    "    \n",
    "    total_positive = np.sum(sorted_y)  \n",
    "    total_negative = len(sorted_y) - total_positive  \n",
    "    \n",
    "    for i in range(num_groups):  \n",
    "        start, end = group_bounds[i], group_bounds[i + 1]  \n",
    "        observed_counts[i] = np.sum(sorted_y[start:end])  \n",
    "        expected_counts[i] = (end - start) * total_positive / len(sorted_y)  \n",
    "        \n",
    "    # Perform chi-squared test  \n",
    "    chi2, p = chi2_contingency(np.array([observed_counts, expected_counts]).T)[:2]  \n",
    "    \n",
    "    dof = num_groups - 2  # Degrees of freedom for chi-squared test\n",
    "      \n",
    "    return chi2, p, dof  \n",
    "\n",
    "chi2, p_value, dof = hosmer_lemeshow_test(test_y,XGB_y_pred)  \n",
    "print(f\"Chi-squared: {chi2}\")  \n",
    "print(f\"P-value: {p_value}\")  \n",
    "print(f\"Degrees of freedom: {dof}\")\n",
    "\n",
    "# Determining Model Calibration Based on P-Value\n",
    "if p_value < 0.05:\n",
    "    print(\"The model is poorly calibrated.\")\n",
    "else:\n",
    "    print(\"The model is well calibrated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "adbeebc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1af627c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(learning_rate=0.005, max_features=2,\n",
       "                           min_samples_leaf=27, min_samples_split=38,\n",
       "                           n_estimators=278, random_state=102030,\n",
       "                           subsample=0.7)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=0.005, max_features=2,\n",
       "                           min_samples_leaf=27, min_samples_split=38,\n",
       "                           n_estimators=278, random_state=102030,\n",
       "                           subsample=0.7)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.005, max_features=2,\n",
       "                           min_samples_leaf=27, min_samples_split=38,\n",
       "                           n_estimators=278, random_state=102030,\n",
       "                           subsample=0.7)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    best_GB = GradientBoostingClassifier(learning_rate=0.005,  \n",
    "                                           n_estimators=278,  \n",
    "                                           min_samples_split=38,  \n",
    "                                           min_samples_leaf=27,  \n",
    "                                           max_depth=3,  \n",
    "                                           max_features=2,  \n",
    "                                           subsample=0.7,\n",
    "                                           random_state=102030)  \n",
    "\n",
    "    best_GB.fit(train_X, train_y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2ee4da2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testAUC: 0.8906467661691542\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8906467661691542"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_gb_pred_proba = best_GB.predict_proba(test_X)[:, 1]\n",
    "test_auc = roc_auc_score(test_y, test_gb_pred_proba)\n",
    "GBboost_y_pred=best_GB.predict(test_X)\n",
    "print(\"testAUC:\", test_auc)\n",
    "fprgb,tprgb,threshold = roc_curve(test_y,test_gb_pred_proba)\n",
    "auc(fprgb,tprgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f6ec2f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8906467661691542"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fprgb,tprgb,threshold = roc_curve(test_y,test_gb_pred_proba)\n",
    "auc(fprgb,tprgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f7196b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original AUC: 0.891\n",
      "95% CI for AUC: (0.828, 0.945)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Calculate ROC curve and AUC for the original data\n",
    "fprgb, tprgb, thresholds = roc_curve(test_y,test_gb_pred_proba )\n",
    "original_auc = auc(fprgb, tprgb)\n",
    "print(\"Original AUC: {:.3f}\".format(original_auc))\n",
    "\n",
    "# Bootstrapping parameters\n",
    "n_bootstraps = 10000  # You can adjust this number as needed\n",
    "auc_scores = []\n",
    "\n",
    "# Bootstrapping process\n",
    "np.random.seed(321)  # Set random seed for reproducibility\n",
    "for _ in range(n_bootstraps):\n",
    "    # Randomly sample test set samples with replacement\n",
    "    bootstrap_indices = np.random.randint(0, len(test_y), size=len(test_y))\n",
    "    bootstrap_y = test_y[bootstrap_indices]\n",
    "    bootstrap_y_score = test_gb_pred_proba[bootstrap_indices]\n",
    "    \n",
    "    # Calculate AUC for each bootstrap sample\n",
    "    fpr_bootstrap, tpr_bootstrap, _ = roc_curve(bootstrap_y, bootstrap_y_score)\n",
    "    auc_bootstrap = auc(fpr_bootstrap, tpr_bootstrap)\n",
    "    auc_scores.append(auc_bootstrap)\n",
    "\n",
    "# Calculate the 95% confidence interval\n",
    "auc_scores = np.array(auc_scores)\n",
    "auc_scores_sorted = np.sort(auc_scores)\n",
    "n = len(auc_scores)\n",
    "lower_idx = int(np.round(n * 0.025))  # Calculate lower bound index\n",
    "upper_idx = int(np.round(n * 0.975))  # Calculate upper bound index\n",
    "auc_lower = auc_scores_sorted[lower_idx]\n",
    "auc_upper = auc_scores_sorted[upper_idx]\n",
    "\n",
    "print(\"95% CI for AUC: ({:.3f}, {:.3f})\".format(auc_lower, auc_upper))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a412067c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC: 0.9233230926779313\n"
     ]
    }
   ],
   "source": [
    "GBboost_train_y_pred=best_GB.predict(train_X)\n",
    "train_GB_pred_proba = best_GB.predict_proba(train_X)[:, 1]\n",
    "train_auc = roc_auc_score(train_y, train_GB_pred_proba)\n",
    "print(\"Train AUC:\", train_auc )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b6fecaca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9233230926779313"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fprGB,tprGB,threshold = roc_curve(train_y,train_GB_pred_proba)\n",
    "auc(fprGB,tprGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac809f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original AUC: 0.923\n",
      "95% CI for AUC: (0.8951, 0.9483)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Calculate ROC curve and AUC for the original data\n",
    "fprGB, tprGB, thresholds = roc_curve(train_y,train_GB_pred_proba)\n",
    "original_auc = auc(fprGB, tprGB)\n",
    "print(\"Original AUC: {:.3f}\".format(original_auc))\n",
    "\n",
    "# Bootstrapping parameters\n",
    "n_bootstraps = 1000  # You can adjust this number as needed\n",
    "auc_scores = []\n",
    "\n",
    "# Bootstrapping process\n",
    "np.random.seed(321)  # Set random seed for reproducibility\n",
    "for _ in range(n_bootstraps):\n",
    "    # Randomly sample train set samples with replacement\n",
    "    bootstrap_indices = np.random.randint(0, len(train_y), size=len(train_y))\n",
    "    bootstrap_y = train_y[bootstrap_indices]\n",
    "    bootstrap_y_score = train_GB_pred_proba[bootstrap_indices]\n",
    "    \n",
    "    # Calculate AUC for each bootstrap sample\n",
    "    fpr_bootstrap, tpr_bootstrap, _ = roc_curve(bootstrap_y, bootstrap_y_score)\n",
    "    auc_bootstrap = auc(fpr_bootstrap, tpr_bootstrap)\n",
    "    auc_scores.append(auc_bootstrap)\n",
    "\n",
    "# Calculate the 95% confidence interval\n",
    "auc_scores = np.array(auc_scores)\n",
    "auc_scores_sorted = np.sort(auc_scores)\n",
    "n = len(auc_scores)\n",
    "lower_idx = int(np.round(n * 0.025))  # Calculate lower bound index\n",
    "upper_idx = int(np.round(n * 0.975))  # Calculate upper bound index\n",
    "auc_lower = auc_scores_sorted[lower_idx]\n",
    "auc_upper = auc_scores_sorted[upper_idx]\n",
    "\n",
    "print(\"95% CI for AUC: ({:.4f}, {:.4f})\".format(auc_lower, auc_upper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb7c20d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Metrics:\n",
      "Sensitivity: 0.8367\n",
      "Specificity: 0.8495\n",
      "PPV (Precision): 0.8146\n",
      "NPV: 0.8681\n",
      "Predictive Accuracy: 0.8438\n",
      "MCC: 0.6844\n",
      "\n",
      "Test Set Metrics:\n",
      "Sensitivity: 0.7463\n",
      "Specificity: 0.8533\n",
      "PPV (Precision): 0.820\n",
      "NPV: 0.7901\n",
      "Predictive Accuracy: 0.8028\n",
      "MCC: 0.6047\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "sensitivity_train, specificity_train, ppv_train, npv_train, predictive_accuracy_train, mcc_train = calculate_metrics(train_y,GBboost_train_y_pred)\n",
    "sensitivity_test, specificity_test, ppv_test, npv_test, predictive_accuracy_test, mcc_test = calculate_metrics(test_y,GBboost_y_pred)\n",
    "\n",
    "print(\"Train Set Metrics:\")\n",
    "print(f\"Sensitivity: {sensitivity_train:.4f}\")\n",
    "print(f\"Specificity: {specificity_train:.4f}\")\n",
    "print(f\"PPV (Precision): {ppv_train:.4f}\")\n",
    "print(f\"NPV: {npv_train:.4f}\")\n",
    "print(f\"Predictive Accuracy: {predictive_accuracy_train:.4f}\")\n",
    "print(f\"MCC: {mcc_train:.4f}\")\n",
    "\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "print(f\"Sensitivity: {sensitivity_test:.4f}\")\n",
    "print(f\"Specificity: {specificity_test:.4f}\")\n",
    "print(f\"PPV (Precision): {ppv_test:.3f}\")\n",
    "print(f\"NPV: {npv_test:.4f}\")\n",
    "print(f\"Predictive Accuracy: {predictive_accuracy_test:.4f}\")\n",
    "print(f\"MCC: {mcc_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1c008b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_GB_y_score =best_GB.predict_proba(test_X)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "774f4f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-squared: 13.931517965112386\n",
      "P-value: 0.12478220479239868\n",
      "Degrees of freedom: 8\n",
      "The model is well calibrated.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "from scipy.stats import chi2_contingency  \n",
    "\n",
    "def hosmer_lemeshow_test(test_y, GBboost_y_pred , num_groups=10):  \n",
    "    # Sort the data based on predicted probabilities  \n",
    "    sorted_indices = np.argsort( GBboost_y_pred )  \n",
    "    sorted_y = test_y[sorted_indices]  \n",
    "    \n",
    "    # Create groups based on the sorted indices  \n",
    "    group_size = len(sorted_y) // num_groups  \n",
    "    group_bounds = np.arange(0, len(sorted_y) + 1, group_size)  \n",
    "    \n",
    "    # Calculate observed and expected counts for each group  \n",
    "    observed_counts = np.zeros(num_groups)  \n",
    "    expected_counts = np.zeros(num_groups)  \n",
    "    \n",
    "    total_positive = np.sum(sorted_y)  \n",
    "    total_negative = len(sorted_y) - total_positive  \n",
    "    \n",
    "    for i in range(num_groups):  \n",
    "        start, end = group_bounds[i], group_bounds[i + 1]  \n",
    "        observed_counts[i] = np.sum(sorted_y[start:end])  \n",
    "        expected_counts[i] = (end - start) * total_positive / len(sorted_y)  \n",
    "        \n",
    "    # Perform chi-squared test  \n",
    "    chi2, p = chi2_contingency(np.array([observed_counts, expected_counts]).T)[:2]  \n",
    "    \n",
    "    dof = num_groups - 2  # Degrees of freedom for chi-squared test\n",
    "      \n",
    "    return chi2, p, dof  \n",
    "\n",
    "chi2, p_value, dof = hosmer_lemeshow_test(test_y, GBboost_y_pred )  \n",
    "print(f\"Chi-squared: {chi2}\")  \n",
    "print(f\"P-value: {p_value}\")  \n",
    "print(f\"Degrees of freedom: {dof}\")\n",
    "\n",
    "\n",
    "# Determining Model Calibration Based on P-Value\n",
    "if p_value < 0.05:\n",
    "    print(\"The model is poorly calibrated.\")\n",
    "else:\n",
    "    print(\"The model is well calibrated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fa9d1304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(bagging_fraction=0.6, bagging_freq=10, feature_fraction=0.9,\n",
       "               lambda_l1=0.7, lambda_l2=1e-05, learning_rate=0.005, max_bin=14,\n",
       "               max_depth=4, min_data_in_leaf=32, n_estimators=600,\n",
       "               num_leaves=12, random_state=123, verbose=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(bagging_fraction=0.6, bagging_freq=10, feature_fraction=0.9,\n",
       "               lambda_l1=0.7, lambda_l2=1e-05, learning_rate=0.005, max_bin=14,\n",
       "               max_depth=4, min_data_in_leaf=32, n_estimators=600,\n",
       "               num_leaves=12, random_state=123, verbose=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.6, bagging_freq=10, feature_fraction=0.9,\n",
       "               lambda_l1=0.7, lambda_l2=1e-05, learning_rate=0.005, max_bin=14,\n",
       "               max_depth=4, min_data_in_leaf=32, n_estimators=600,\n",
       "               num_leaves=12, random_state=123, verbose=-1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "best_params_LGBM = {\n",
    "    'lambda_l1': 0.7,\n",
    "    'lambda_l2': 1e-05,\n",
    "    'learning_rate': 0.005,\n",
    "    'n_estimators': 600,\n",
    "    'max_depth': 4,\n",
    "    'num_leaves': 12,\n",
    "    'max_bin': 14,\n",
    "    'min_data_in_leaf': 32,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.6,\n",
    "    'bagging_freq': 10,\n",
    "    'random_state': 123,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "\n",
    "best_LGBM = lgb.LGBMClassifier(**best_params_LGBM)\n",
    "best_LGBM.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a0906f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8378378378378378\n",
      "Training AUC： 0.9128081340062908\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "train_y_pred = best_LGBM.predict(train_X)\n",
    "train_accuracy = accuracy_score(train_y, train_y_pred)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "train_y_lgbm_prob = best_LGBM.predict_proba(train_X)[:, 1]\n",
    "train_auc = roc_auc_score(train_y, train_y_prob)\n",
    "print(\"Training AUC：\", train_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d550aed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_accuracy: 0.823943661971831\n",
      "Test AUC: 0.8920398009950249\n"
     ]
    }
   ],
   "source": [
    "y_score_LGBM = best_LGBM.predict_proba(test_X)[:, 1]\n",
    "LGBM_y_pred=best_LGBM.predict(test_X)\n",
    "test_accuracy = accuracy_score(test_y, LGBM_y_pred)\n",
    "print(\"Test_accuracy:\", test_accuracy)\n",
    "fprlgbm, tprlgbm, threshold = roc_curve(test_y, y_score_LGBM)\n",
    "test_auc = roc_auc_score(test_y, y_score_LGBM )\n",
    "\n",
    "print(\"Test AUC:\", test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "42f0827b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Metrics:\n",
      "Sensitivity: 0.8231\n",
      "Specificity: 0.8495\n",
      "PPV (Precision): 0.8121\n",
      "NPV: 0.8587\n",
      "Predictive Accuracy: 0.8378\n",
      "MCC: 0.6717\n",
      "\n",
      "Test Set Metrics:\n",
      "Sensitivity: 0.7761\n",
      "Specificity: 0.8667\n",
      "PPV (Precision): 0.839\n",
      "NPV: 0.8125\n",
      "Predictive Accuracy: 0.8239\n",
      "MCC: 0.6470\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "sensitivity_train, specificity_train, ppv_train, npv_train, predictive_accuracy_train, mcc_train = calculate_metrics(train_y, train_y_pred)\n",
    "sensitivity_test, specificity_test, ppv_test, npv_test, predictive_accuracy_test, mcc_test = calculate_metrics(test_y, LGBM_y_pred)\n",
    "\n",
    "print(\"Train Set Metrics:\")\n",
    "print(f\"Sensitivity: {sensitivity_train:.4f}\")\n",
    "print(f\"Specificity: {specificity_train:.4f}\")\n",
    "print(f\"PPV (Precision): {ppv_train:.4f}\")\n",
    "print(f\"NPV: {npv_train:.4f}\")\n",
    "print(f\"Predictive Accuracy: {predictive_accuracy_train:.4f}\")\n",
    "print(f\"MCC: {mcc_train:.4f}\")\n",
    "\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "print(f\"Sensitivity: {sensitivity_test:.4f}\")\n",
    "print(f\"Specificity: {specificity_test:.4f}\")\n",
    "print(f\"PPV (Precision): {ppv_test:.3f}\")\n",
    "print(f\"NPV: {npv_test:.4f}\")\n",
    "print(f\"Predictive Accuracy: {predictive_accuracy_test:.4f}\")\n",
    "print(f\"MCC: {mcc_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "98580010",
   "metadata": {},
   "outputs": [],
   "source": [
    "fprLGBM, tprLGBM, thresholds= roc_curve(train_y, train_y_lgbm_prob)\n",
    "fprlgbm, tprlgbm, thresholds = roc_curve(test_y, y_score_LGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7afcc8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original AUC: 0.892\n",
      "95% CI for AUC: (0.830, 0.946)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Calculate ROC curve and AUC for the original data\n",
    "fprlgbm, tprlgbm, thresholds = roc_curve(test_y,y_score_LGBM)\n",
    "original_auc = auc(fprlgbm, tprlgbm)\n",
    "print(\"Original AUC: {:.3f}\".format(original_auc))\n",
    "\n",
    "# Bootstrapping parameters\n",
    "n_bootstraps = 10000  # You can adjust this number as needed\n",
    "auc_scores = []\n",
    "\n",
    "# Bootstrapping process\n",
    "np.random.seed(321)  # Set random seed for reproducibility\n",
    "for _ in range(n_bootstraps):\n",
    "    # Randomly sample test set samples with replacement\n",
    "    bootstrap_indices = np.random.randint(0, len(test_y), size=len(test_y))\n",
    "    bootstrap_y = test_y[bootstrap_indices]\n",
    "    bootstrap_y_score = y_score_LGBM [bootstrap_indices]\n",
    "    \n",
    "    # Calculate AUC for each bootstrap sample\n",
    "    fpr_bootstrap, tpr_bootstrap, _ = roc_curve(bootstrap_y, bootstrap_y_score)\n",
    "    auc_bootstrap = auc(fpr_bootstrap, tpr_bootstrap)\n",
    "    auc_scores.append(auc_bootstrap)\n",
    "\n",
    "# Calculate the 95% confidence interval\n",
    "auc_scores = np.array(auc_scores)\n",
    "auc_scores_sorted = np.sort(auc_scores)\n",
    "n = len(auc_scores)\n",
    "lower_idx = int(np.round(n * 0.025))  # Calculate lower bound index\n",
    "upper_idx = int(np.round(n * 0.975))  # Calculate upper bound index\n",
    "auc_lower = auc_scores_sorted[lower_idx]\n",
    "auc_upper = auc_scores_sorted[upper_idx]\n",
    "\n",
    "print(\"95% CI for AUC: ({:.3f}, {:.3f})\".format(auc_lower, auc_upper))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a4fa0d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original AUC: 0.917\n",
      "95% CI for AUC: (0.8871, 0.9442)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Calculate ROC curve and AUC for the original data\n",
    "fprLGBM, tprLGBM, thresholds = roc_curve(train_y,train_y_lgbm_prob )\n",
    "original_auc = auc(fprLGBM, tprLGBM)\n",
    "print(\"Original AUC: {:.3f}\".format(original_auc))\n",
    "\n",
    "# Bootstrapping parameters\n",
    "n_bootstraps = 1000  # You can adjust this number as needed\n",
    "auc_scores = []\n",
    "\n",
    "# Bootstrapping process\n",
    "np.random.seed(321)  # Set random seed for reproducibility\n",
    "for _ in range(n_bootstraps):\n",
    "    # Randomly sample train set samples with replacement\n",
    "    bootstrap_indices = np.random.randint(0, len(train_y), size=len(train_y))\n",
    "    bootstrap_y = train_y[bootstrap_indices]\n",
    "    bootstrap_y_score = train_y_lgbm_prob[bootstrap_indices]\n",
    "    \n",
    "    # Calculate AUC for each bootstrap sample\n",
    "    fpr_bootstrap, tpr_bootstrap, _ = roc_curve(bootstrap_y, bootstrap_y_score)\n",
    "    auc_bootstrap = auc(fpr_bootstrap, tpr_bootstrap)\n",
    "    auc_scores.append(auc_bootstrap)\n",
    "\n",
    "# Calculate the 95% confidence interval\n",
    "auc_scores = np.array(auc_scores)\n",
    "auc_scores_sorted = np.sort(auc_scores)\n",
    "n = len(auc_scores)\n",
    "lower_idx = int(np.round(n * 0.025))  # Calculate lower bound index\n",
    "upper_idx = int(np.round(n * 0.975))  # Calculate upper bound index\n",
    "auc_lower = auc_scores_sorted[lower_idx]\n",
    "auc_upper = auc_scores_sorted[upper_idx]\n",
    "\n",
    "print(\"95% CI for AUC: ({:.4f}, {:.4f})\".format(auc_lower, auc_upper))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "60b5acb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-squared: 14.752584657314266\n",
      "P-value: 0.09796011603922684\n",
      "Degrees of freedom: 8\n",
      "The model is well calibrated.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "from scipy.stats import chi2_contingency  \n",
    "\n",
    "def hosmer_lemeshow_test(test_y, LGBM_y_pred , num_groups=10):  \n",
    "    # Sort the data based on predicted probabilities  \n",
    "    sorted_indices = np.argsort( LGBM_y_pred)  \n",
    "    sorted_y = test_y[sorted_indices]  \n",
    "    \n",
    "    # Create groups based on the sorted indices  \n",
    "    group_size = len(sorted_y) // num_groups  \n",
    "    group_bounds = np.arange(0, len(sorted_y) + 1, group_size)  \n",
    "    \n",
    "    # Calculate observed and expected counts for each group  \n",
    "    observed_counts = np.zeros(num_groups)  \n",
    "    expected_counts = np.zeros(num_groups)  \n",
    "    \n",
    "    total_positive = np.sum(sorted_y)  \n",
    "    total_negative = len(sorted_y) - total_positive  \n",
    "    \n",
    "    for i in range(num_groups):  \n",
    "        start, end = group_bounds[i], group_bounds[i + 1]  \n",
    "        observed_counts[i] = np.sum(sorted_y[start:end])  \n",
    "        expected_counts[i] = (end - start) * total_positive / len(sorted_y)  \n",
    "        \n",
    "    # Perform chi-squared test  \n",
    "    chi2, p = chi2_contingency(np.array([observed_counts, expected_counts]).T)[:2]  \n",
    "    \n",
    "    dof = num_groups - 2  # Degrees of freedom for chi-squared test\n",
    "      \n",
    "    return chi2, p, dof  \n",
    "\n",
    "chi2, p_value, dof = hosmer_lemeshow_test(test_y,LGBM_y_pred)  \n",
    "print(f\"Chi-squared: {chi2}\")  \n",
    "print(f\"P-value: {p_value}\")  \n",
    "print(f\"Degrees of freedom: {dof}\")\n",
    "\n",
    "# Determining Model Calibration Based on P-Value\n",
    "if p_value < 0.05:\n",
    "    print(\"The model is poorly calibrated.\")\n",
    "else:\n",
    "    print(\"The model is well calibrated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "67480dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z score = 0.15964;\n",
      "p value = 0.87316;\n",
      "There is NO significant difference\n",
      "Comparison between LGBM and GB:\n",
      "z score = 0.15964;\n",
      "p value = 0.87316;\n",
      "There is NO significant difference\n",
      "\n",
      "\n",
      "z score = 0.60502;\n",
      "p value = 0.54516;\n",
      "There is NO significant difference\n",
      "Comparison between LGBM and XGB:\n",
      "z score = 0.60502;\n",
      "p value = 0.54516;\n",
      "There is NO significant difference\n",
      "\n",
      "\n",
      "z score = 1.43431;\n",
      "p value = 0.15148;\n",
      "There is NO significant difference\n",
      "Comparison between LGBM and RF:\n",
      "z score = 1.43431;\n",
      "p value = 0.15148;\n",
      "There is NO significant difference\n",
      "\n",
      "\n",
      "z score = 0.40568;\n",
      "p value = 0.68498;\n",
      "There is NO significant difference\n",
      "Comparison between GB and XGB:\n",
      "z score = 0.40568;\n",
      "p value = 0.68498;\n",
      "There is NO significant difference\n",
      "\n",
      "\n",
      "z score = 1.89462;\n",
      "p value = 0.05814;\n",
      "There is NO significant difference\n",
      "Comparison between GB and RF:\n",
      "z score = 1.89462;\n",
      "p value = 0.05814;\n",
      "There is NO significant difference\n",
      "\n",
      "\n",
      "z score = 1.40008;\n",
      "p value = 0.16149;\n",
      "There is NO significant difference\n",
      "Comparison between XGB and RF:\n",
      "z score = 1.40008;\n",
      "p value = 0.16149;\n",
      "There is NO significant difference\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.stats as st\n",
    "from sklearn import metrics\n",
    "\n",
    "class DelongTest():\n",
    "    def __init__(self, preds1, preds2, label, threshold=0.05):\n",
    "        self._preds1 = preds1\n",
    "        self._preds2 = preds2\n",
    "        self._label = label\n",
    "        self.threshold = threshold\n",
    "        self._show_result()\n",
    "\n",
    "    def _auc(self, X, Y) -> float:\n",
    "        return 1/(len(X)*len(Y)) * sum([self._kernel(x, y) for x in X for y in Y])\n",
    "\n",
    "    def _kernel(self, X, Y) -> float:\n",
    "        return .5 if Y == X else int(Y < X)\n",
    "\n",
    "    def _structural_components(self, X, Y) -> list:\n",
    "        V10 = [1/len(Y) * sum([self._kernel(x, y) for y in Y]) for x in X]\n",
    "        V01 = [1/len(X) * sum([self._kernel(x, y) for x in X]) for y in Y]\n",
    "        return V10, V01\n",
    "\n",
    "    def _get_S_entry(self, V_A, V_B, auc_A, auc_B) -> float:\n",
    "        return 1/(len(V_A)-1) * sum([(a-auc_A)*(b-auc_B) for a, b in zip(V_A, V_B)])\n",
    "    \n",
    "    def _z_score(self, var_A, var_B, covar_AB, auc_A, auc_B):\n",
    "        return (auc_A - auc_B) / ((var_A + var_B - 2*covar_AB)**(.5) + 1e-8)\n",
    "\n",
    "    def _group_preds_by_label(self, preds, actual) -> list:\n",
    "        X = [p for (p, a) in zip(preds, actual) if a]\n",
    "        Y = [p for (p, a) in zip(preds, actual) if not a]\n",
    "        return X, Y\n",
    "\n",
    "    def _compute_z_p(self):\n",
    "        X_A, Y_A = self._group_preds_by_label(self._preds1, self._label)\n",
    "        X_B, Y_B = self._group_preds_by_label(self._preds2, self._label)\n",
    "\n",
    "        V_A10, V_A01 = self._structural_components(X_A, Y_A)\n",
    "        V_B10, V_B01 = self._structural_components(X_B, Y_B)\n",
    "\n",
    "        auc_A = self._auc(X_A, Y_A)\n",
    "        auc_B = self._auc(X_B, Y_B)\n",
    "\n",
    "        var_A = (self._get_S_entry(V_A10, V_A10, auc_A, auc_A) * 1/len(V_A10) + self._get_S_entry(V_A01, V_A01, auc_A, auc_A) * 1/len(V_A01))\n",
    "        var_B = (self._get_S_entry(V_B10, V_B10, auc_B, auc_B) * 1/len(V_B10) + self._get_S_entry(V_B01, V_B01, auc_B, auc_B) * 1/len(V_B01))\n",
    "        covar_AB = (self._get_S_entry(V_A10, V_B10, auc_A, auc_B) * 1/len(V_A10) + self._get_S_entry(V_A01, V_B01, auc_A, auc_B) * 1/len(V_A01))\n",
    "\n",
    "        z = self._z_score(var_A, var_B, covar_AB, auc_A, auc_B)\n",
    "        p = st.norm.sf(abs(z)) * 2\n",
    "\n",
    "        return z, p\n",
    "\n",
    "    def _show_result(self):\n",
    "        z, p = self._compute_z_p()\n",
    "        print(f\"z score = {z:.5f};\\np value = {p:.5f};\")\n",
    "        if p < self.threshold:\n",
    "            print(\"There is a significant difference\")\n",
    "        else:\n",
    "            print(\"There is NO significant difference\")\n",
    "\n",
    "# Assuming you have defined predictions and model_names appropriately\n",
    "predictions = [y_score_LGBM, test_gb_pred_proba, XGBboost_y_score, RF_y_score]\n",
    "model_names = [\"LGBM\", \"GB\", \"XGB\", \"RF\"]\n",
    "\n",
    "# Compare each pair of models\n",
    "for i in range(len(predictions)):\n",
    "    for j in range(i+1, len(predictions)):\n",
    "        model1_preds = predictions[i]\n",
    "        model2_preds = predictions[j]\n",
    "        model1_name = model_names[i]\n",
    "        model2_name = model_names[j]\n",
    "        \n",
    "        # Use the DelongTest class to compare predictions between two models\n",
    "        delong_test = DelongTest(model1_preds, model2_preds, test_y)\n",
    "        print(f\"Comparison between {model1_name} and {model2_name}:\")\n",
    "        delong_test._show_result()\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "133e5478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUCs:\n",
      "LGBM: 0.9172701338599956\n",
      "GB: 0.9233230926779313\n",
      "XGB: 0.9128081340062908\n",
      "RF: 0.915697461780411\n",
      "z score = -1.77603;\n",
      "p value = 0.07573;\n",
      "There is NO significant difference\n",
      "Comparison between LGBM and GB on the training set:\n",
      "z score = -1.77603;\n",
      "p value = 0.07573;\n",
      "There is NO significant difference\n",
      "\n",
      "\n",
      "z score = 1.20354;\n",
      "p value = 0.22877;\n",
      "There is NO significant difference\n",
      "Comparison between LGBM and XGB on the training set:\n",
      "z score = 1.20354;\n",
      "p value = 0.22877;\n",
      "There is NO significant difference\n",
      "\n",
      "\n",
      "z score = 0.48530;\n",
      "p value = 0.62747;\n",
      "There is NO significant difference\n",
      "Comparison between LGBM and RF on the training set:\n",
      "z score = 0.48530;\n",
      "p value = 0.62747;\n",
      "There is NO significant difference\n",
      "\n",
      "\n",
      "z score = 2.65714;\n",
      "p value = 0.00788;\n",
      "There is a significant difference\n",
      "Comparison between GB and XGB on the training set:\n",
      "z score = 2.65714;\n",
      "p value = 0.00788;\n",
      "There is a significant difference\n",
      "\n",
      "\n",
      "z score = 2.48896;\n",
      "p value = 0.01281;\n",
      "There is a significant difference\n",
      "Comparison between GB and RF on the training set:\n",
      "z score = 2.48896;\n",
      "p value = 0.01281;\n",
      "There is a significant difference\n",
      "\n",
      "\n",
      "z score = -1.06333;\n",
      "p value = 0.28763;\n",
      "There is NO significant difference\n",
      "Comparison between XGB and RF on the training set:\n",
      "z score = -1.06333;\n",
      "p value = 0.28763;\n",
      "There is NO significant difference\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.stats as st\n",
    "from sklearn import metrics\n",
    "\n",
    "class DelongTest():\n",
    "    def __init__(self, preds1, preds2, label, threshold=0.05):\n",
    "        self._preds1 = preds1\n",
    "        self._preds2 = preds2\n",
    "        self._label = label\n",
    "        self.threshold = threshold\n",
    "        self._show_result()\n",
    "\n",
    "    def _auc(self, X, Y) -> float:\n",
    "        return 1/(len(X)*len(Y)) * sum([self._kernel(x, y) for x in X for y in Y])\n",
    "\n",
    "    def _kernel(self, X, Y) -> float:\n",
    "        return .5 if Y == X else int(Y < X)\n",
    "\n",
    "    def _structural_components(self, X, Y) -> list:\n",
    "        V10 = [1/len(Y) * sum([self._kernel(x, y) for y in Y]) for x in X]\n",
    "        V01 = [1/len(X) * sum([self._kernel(x, y) for x in X]) for y in Y]\n",
    "        return V10, V01\n",
    "\n",
    "    def _get_S_entry(self, V_A, V_B, auc_A, auc_B) -> float:\n",
    "        return 1/(len(V_A)-1) * sum([(a-auc_A)*(b-auc_B) for a, b in zip(V_A, V_B)])\n",
    "    \n",
    "    def _z_score(self, var_A, var_B, covar_AB, auc_A, auc_B):\n",
    "        return (auc_A - auc_B) / ((var_A + var_B - 2*covar_AB)**(.5) + 1e-8)\n",
    "\n",
    "    def _group_preds_by_label(self, preds, actual) -> list:\n",
    "        X = [p for (p, a) in zip(preds, actual) if a]\n",
    "        Y = [p for (p, a) in zip(preds, actual) if not a]\n",
    "        return X, Y\n",
    "\n",
    "    def _compute_z_p(self):\n",
    "        X_A, Y_A = self._group_preds_by_label(self._preds1, self._label)\n",
    "        X_B, Y_B = self._group_preds_by_label(self._preds2, self._label)\n",
    "\n",
    "        V_A10, V_A01 = self._structural_components(X_A, Y_A)\n",
    "        V_B10, V_B01 = self._structural_components(X_B, Y_B)\n",
    "\n",
    "        auc_A = self._auc(X_A, Y_A)\n",
    "        auc_B = self._auc(X_B, Y_B)\n",
    "\n",
    "        var_A = (self._get_S_entry(V_A10, V_A10, auc_A, auc_A) * 1/len(V_A10) + self._get_S_entry(V_A01, V_A01, auc_A, auc_A) * 1/len(V_A01))\n",
    "        var_B = (self._get_S_entry(V_B10, V_B10, auc_B, auc_B) * 1/len(V_B10) + self._get_S_entry(V_B01, V_B01, auc_B, auc_B) * 1/len(V_B01))\n",
    "        covar_AB = (self._get_S_entry(V_A10, V_B10, auc_A, auc_B) * 1/len(V_A10) + self._get_S_entry(V_A01, V_B01, auc_A, auc_B) * 1/len(V_A01))\n",
    "\n",
    "        z = self._z_score(var_A, var_B, covar_AB, auc_A, auc_B)\n",
    "        p = st.norm.sf(abs(z)) * 2\n",
    "\n",
    "        return z, p\n",
    "\n",
    "    def _show_result(self):\n",
    "        z, p = self._compute_z_p()\n",
    "        print(f\"z score = {z:.5f};\\np value = {p:.5f};\")\n",
    "        if p < self.threshold:\n",
    "            print(\"There is a significant difference\")\n",
    "        else:\n",
    "            print(\"There is NO significant difference\")\n",
    "\n",
    "# Define your best models and training set predictions\n",
    "train_y_lgbm_prob = best_LGBM.predict_proba(train_X)[:, 1]\n",
    "train_gb_pred_proba = best_GB.predict_proba(train_X)[:, 1]\n",
    "train_xgb_pred_proba = best_model_XGB.predict_proba(train_X)[:, 1]\n",
    "train_rf_pred_proba = best_RF.predict_proba(train_X)[:, 1]\n",
    "\n",
    "# Calculate AUCs for the training set\n",
    "train_auc_lgbm = roc_auc_score(train_y, train_y_lgbm_prob)\n",
    "train_auc_gb = roc_auc_score(train_y, train_gb_pred_proba)\n",
    "train_auc_xgb = roc_auc_score(train_y, train_xgb_pred_proba)\n",
    "train_auc_rf = roc_auc_score(train_y, train_rf_pred_proba)\n",
    "\n",
    "print(f\"Training AUCs:\\nLGBM: {train_auc_lgbm}\\nGB: {train_auc_gb}\\nXGB: {train_auc_xgb}\\nRF: {train_auc_rf}\")\n",
    "\n",
    "# Assuming you have defined predictions and model_names appropriately for the training set\n",
    "train_predictions = [train_y_lgbm_prob, train_gb_pred_proba, train_xgb_pred_proba, train_rf_pred_proba]\n",
    "train_model_names = [\"LGBM\", \"GB\", \"XGB\", \"RF\"]\n",
    "\n",
    "# Compare each pair of models on the training set\n",
    "for i in range(len(train_predictions)):\n",
    "    for j in range(i+1, len(train_predictions)):\n",
    "        model1_preds = train_predictions[i]\n",
    "        model2_preds = train_predictions[j]\n",
    "        model1_name = train_model_names[i]\n",
    "        model2_name = train_model_names[j]\n",
    "        \n",
    "        # Use the DelongTest class to compare predictions between two models\n",
    "        delong_test = DelongTest(model1_preds, model2_preds, train_y)\n",
    "        print(f\"Comparison between {model1_name} and {model2_name} on the training set:\")\n",
    "        delong_test._show_result()\n",
    "        print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b25d3781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class DelongTest():\n",
    "    def __init__(self, preds1, preds2, label, model1_name, model2_name, threshold=0.05):\n",
    "        self._preds1 = preds1\n",
    "        self._preds2 = preds2\n",
    "        self._label = label\n",
    "        self.model1_name = model1_name\n",
    "        self.model2_name = model2_name\n",
    "        self.threshold = threshold\n",
    "        self.results = self._compute_result()\n",
    "\n",
    "    def _auc(self, X, Y) -> float:\n",
    "        return 1 / (len(X) * len(Y)) * sum([self._kernel(x, y) for x in X for y in Y])\n",
    "\n",
    "    def _kernel(self, X, Y) -> float:\n",
    "        return 0.5 if Y == X else int(Y < X)\n",
    "\n",
    "    def _structural_components(self, X, Y) -> list:\n",
    "        V10 = [1 / len(Y) * sum([self._kernel(x, y) for y in Y]) for x in X]\n",
    "        V01 = [1 / len(X) * sum([self._kernel(x, y) for x in X]) for y in Y]\n",
    "        return V10, V01\n",
    "\n",
    "    def _get_S_entry(self, V_A, V_B, auc_A, auc_B) -> float:\n",
    "        return 1 / (len(V_A) - 1) * sum([(a - auc_A) * (b - auc_B) for a, b in zip(V_A, V_B)])\n",
    "\n",
    "    def _z_score(self, var_A, var_B, covar_AB, auc_A, auc_B):\n",
    "        return (auc_A - auc_B) / ((var_A + var_B - 2 * covar_AB) ** (.5) + 1e-8)\n",
    "\n",
    "    def _group_preds_by_label(self, preds, actual) -> list:\n",
    "        X = [p for (p, a) in zip(preds, actual) if a]\n",
    "        Y = [p for (p, a) in zip(preds, actual) if not a]\n",
    "        return X, Y\n",
    "\n",
    "    def _compute_result(self):\n",
    "        X_A, Y_A = self._group_preds_by_label(self._preds1, self._label)\n",
    "        X_B, Y_B = self._group_preds_by_label(self._preds2, self._label)\n",
    "\n",
    "        V_A10, V_A01 = self._structural_components(X_A, Y_A)\n",
    "        V_B10, V_B01 = self._structural_components(X_B, Y_B)\n",
    "\n",
    "        auc_A = self._auc(X_A, Y_A)\n",
    "        auc_B = self._auc(X_B, Y_B)\n",
    "\n",
    "        var_A = (self._get_S_entry(V_A10, V_A10, auc_A, auc_A) * 1 / len(V_A10) + self._get_S_entry(V_A01, V_A01,\n",
    "                                                                                                      auc_A,\n",
    "                                                                                                      auc_A) * 1 / len(\n",
    "            V_A01))\n",
    "        var_B = (self._get_S_entry(V_B10, V_B10, auc_B, auc_B) * 1 / len(V_B10) + self._get_S_entry(V_B01, V_B01,\n",
    "                                                                                                      auc_B,\n",
    "                                                                                                      auc_B) * 1 / len(\n",
    "            V_B01))\n",
    "        covar_AB = (self._get_S_entry(V_A10, V_B10, auc_A, auc_B) * 1 / len(V_A10) + self._get_S_entry(V_A01,\n",
    "                                                                                                       V_B01, auc_A,\n",
    "                                                                                                       auc_B) * 1 / len(\n",
    "            V_A01))\n",
    "\n",
    "        z = self._z_score(var_A, var_B, covar_AB, auc_A, auc_B)\n",
    "        p = st.norm.sf(abs(z)) * 2\n",
    "\n",
    "        result = {\n",
    "            \"Model 1\": self.model1_name,\n",
    "            \"Model 2\": self.model2_name,\n",
    "            \"z score\": z,\n",
    "            \"p value\": p,\n",
    "            \"Significant Difference\": \"Yes\" if p < self.threshold else \"No\"\n",
    "        }\n",
    "        return result\n",
    "\n",
    "\n",
    "# Create an empty list to store the results\n",
    "results_list = []\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    for j in range(i + 1, len(predictions)):\n",
    "        model1_preds = predictions[i]\n",
    "        model2_preds = predictions[j]\n",
    "        model1_name = model_names[i]\n",
    "        model2_name = model_names[j]\n",
    "\n",
    "        delong_test = DelongTest(model1_preds, model2_preds, test_y, model1_name, model2_name)\n",
    "        results_list.append(delong_test.results)\n",
    "\n",
    "# Convert the list of results into a DataFrame\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "#results_df.to_csv(\"model_comparison_results1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2776bd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM Brier score: 0.1320138283556927\n",
      "GB Brier score: 0.1427594910326072\n",
      "XGB Brier score: 0.13496849132066688\n",
      "RF Brier score: 0.14742283265438752\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "# Brier \n",
    "LGBM_brier_score = brier_score_loss(test_y, y_score_LGBM)\n",
    "GB_brier_score = brier_score_loss(test_y, test_gb_pred_proba)\n",
    "XGB_brier_score = brier_score_loss(test_y, XGBboost_y_score)\n",
    "RF_brier_score = brier_score_loss(test_y, RF_y_score)\n",
    "\n",
    "print(\"LGBM Brier score:\", LGBM_brier_score)\n",
    "print(\"GB Brier score:\", GB_brier_score)\n",
    "print(\"XGB Brier score:\", XGB_brier_score)\n",
    "print(\"RF Brier score:\", RF_brier_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf11e55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9920a036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f1625f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8bb27b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25773593",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710b65b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6d4c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2dc4eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9291a06c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038f56a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeb8e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc4f0e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa34f3d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
